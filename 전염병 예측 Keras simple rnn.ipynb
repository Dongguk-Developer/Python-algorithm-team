{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPeNoo641QGV52DPgVLaY5h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#개발 환경 만들기\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from pandas import read_csv"],"metadata":{"id":"jkmjxbA2iJj1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 가져오기\n","!git clone https://github.com/yhlee1627/deeplearning.git\n","dataframe = read_csv('/content/deeplearning/corona_daily.csv', usecols=[1], engine='python', skipfooter=3) #secols=[3]는 사용할 데이터를 의미 사용할 데이터가 4번째 열에 있는 확진자 수이므로 3(파이썬은 0부터 시작하죠?)을 넣어줍니다. 마지막 engine='python'은 사용할 언어를 의미\n","print(dataframe)\n","dataset = dataframe.values\n","dataset = dataset.astype('float32')#지금 읽어온 데이터는 정수형 데이터이므로 정수형 데이터를 소수점 단위까지 나누기 위해서는 실수로 바꿔 줄 필요가 있다"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTD6gbaMiX4u","executionInfo":{"status":"ok","timestamp":1726988589320,"user_tz":-540,"elapsed":1069,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"9a07ee2a-4baf-402e-a6ce-56db57b95fbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'deeplearning'...\n","remote: Enumerating objects: 5, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (5/5), done.\n","     Inspected\n","0         1352\n","1         2097\n","2         2598\n","3         3110\n","4         4325\n","..         ...\n","107     820289\n","108     826437\n","109     839475\n","110     852876\n","111     868666\n","\n","[112 rows x 1 columns]\n"]}]},{"cell_type":"code","source":["#데이터 정규화 및 분류하기\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","#정규화 scaler 방식 사용 데이터를 정규화하는 범위를 0~1 사이의 값(feature_range=(0, 1))으로 결정\n","Dataset = scaler.fit_transform(dataset)\n"," #fit_transform 함수를 사용하여 데이터를 정규화 정규화한 데이터를 Dataset으로 정함\n","train_data, test_data = train_test_split(Dataset, test_size=0.2, shuffle=False)\n","#train_test_split 함수를 사용하여 전체 데이터를 훈련 데이터와 검증 데이터로 분류\n","#분류할 데이터(Dataset), 검증 데이터 비율(test_size=0.2), 추출하는 방법(shuffle=False)\n","print(len(train_data), len(test_data))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiVETiM8iaPV","executionInfo":{"status":"ok","timestamp":1726988589320,"user_tz":-540,"elapsed":14,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"128af810-ab40-444e-afe9-d24cdfe1b184"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["89 23\n"]}]},{"cell_type":"code","source":["#데이터 형태 바꾸기\n","def create_dataset(dataset, look_back):\n","    x_data = []\n","    y_data = []\n","    #배열([])을 사용하여 각각 x_data와 y_data를 넣을 수 있는 공간을 만듬\n","    for i in range(len(dataset)-look_back-1):\n","        data = dataset[i:(i+look_back), 0]\n","        x_data.append(data)\n","        y_data.append(dataset[i + look_back, 0])\n","    return np.array(x_data), np.array(y_data)"],"metadata":{"id":"tfAyySshibcP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 입력 데이터 생성하기\n","look_back = 3\n","x_train, y_train = create_dataset(train_data, look_back)\n","#create_dataset 함수를 호출\n","#첫 번째 인자에 훈련 데이터(train_data)를 두 번째 인자에 look_back\n","x_test, y_test = create_dataset(test_data, look_back)\n","#첫 번째 인자에 검증 데이터(test_data)를 넣습니다. 그리고 두 번째 인자에 look_back\n","print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"kQjGuLnsicls","executionInfo":{"status":"error","timestamp":1727175720225,"user_tz":-540,"elapsed":793,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"07c1d982-3133-457c-f60a-c68704bdbda3"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'create_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b558cfa11cb2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 입력 데이터 생성하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlook_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#create_dataset 함수를 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#첫 번째 인자에 훈련 데이터(train_data)를 두 번째 인자에 look_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_dataset' is not defined"]}]},{"cell_type":"code","source":["#인공지능 모델에 넣어줄 형태로 변환하기\n","X_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n","#형태를 바꿔 주는 함수(reshape) 함수의 첫 번째에는 바꿀 데이터, 두 번째에는 어떤 형태로 바꿀지\n","X_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n","print(X_train.shape)\n","print(X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHjdWYZJid6r","executionInfo":{"status":"ok","timestamp":1726988589321,"user_tz":-540,"elapsed":8,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"1b5557db-321f-419c-d1bf-b8776e78f065"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(85, 1, 3)\n","(19, 1, 3)\n"]}]},{"cell_type":"code","source":["#인공지능 모델 만들기\n","model = Sequential()\n","#model이라는 인공지능 모델을 만들겠습니다. 이 모델은 시퀀셜(Sequential) 모델입니다.\n","model.add(SimpleRNN(3, input_shape=(1, look_back)))\n","#RNN 기법 중 SimpleRNN을 사용\n","model.add(Dense(1, activation=\"linear\"))\n","#최종 예측 값(즉 여기선 확진자수 노드는 1개)\n","model.compile(loss='mse', optimizer='adam')\n","#인공지능을 계산하는 방법을 결정\n","# 손실 함수는 mse(평균 제곱 오차, mean_squared_error)로, 옵티마이저는 adam 옵티마이저를 사용\n","#다양한 손실 함수 중 왜 하필이면 평균 제곱 오차를 사용할까요? 바로 실제 확진자의 수와 예측한 값의 차이를 바탕으로 오차를 나타낼 수 있기 때문입니다.\n","model.summary()\n","#생성된 모델을 요약\n","# Model: \"sequential_1\"는 첫 번째 순서로 만든 순차 모델이라는 의미입니다. (실습 환경에 따라 숫자는 달라질 수 있습니다.)\n","#simple_rnn (Simple RNN)은 SimpleRNN을 사용하였다는 의미입니다\n","#Output Shape에서 볼 수 있듯이 총 노드의 수는 3개입니다.\n","#Param은 simple_rnn의 파라미터(가중치와 편향 값)의 수를 의미합니다.\n","#dense (Dense)는 출력층에서의 형태 및 파라미터 수를 의미합니다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"rNDvAXGZifBm","executionInfo":{"status":"ok","timestamp":1726988589831,"user_tz":-540,"elapsed":515,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"f96a299e-0582-49ee-bb25-c49c73f793cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m21\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m4\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25\u001b[0m (100.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (100.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25\u001b[0m (100.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (100.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["#모델 학습시키기\n","model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)\n","#입력 데이터(x_train) 출력 데이터(y_train), 반복 횟수(epochs=100), 한 번에 학습시킬 데이터의 양(batch_size=1)을 설정"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_36T0GWigly","executionInfo":{"status":"ok","timestamp":1726988624663,"user_tz":-540,"elapsed":34837,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"6337ed3f-4698-477b-adf0-59dbc7d84feb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1185\n","Epoch 2/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0227\n","Epoch 3/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130\n","Epoch 4/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077\n","Epoch 5/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0049\n","Epoch 6/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024\n","Epoch 7/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0020\n","Epoch 8/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011\n","Epoch 9/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010\n","Epoch 10/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011\n","Epoch 11/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011\n","Epoch 12/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011\n","Epoch 13/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012\n","Epoch 14/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6388e-04\n","Epoch 15/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1375e-04\n","Epoch 16/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011\n","Epoch 17/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5170e-04\n","Epoch 18/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4003e-04\n","Epoch 19/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9472e-04\n","Epoch 20/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4298e-04\n","Epoch 21/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4240e-04\n","Epoch 22/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0195e-04\n","Epoch 23/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8213e-04\n","Epoch 24/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6082e-04\n","Epoch 25/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2249e-04\n","Epoch 26/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7000e-04\n","Epoch 27/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0713e-04\n","Epoch 28/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0569e-04\n","Epoch 29/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6519e-04\n","Epoch 30/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4312e-04\n","Epoch 31/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7752e-04\n","Epoch 32/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2783e-04\n","Epoch 33/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5647e-04\n","Epoch 34/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8469e-04\n","Epoch 35/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6901e-04\n","Epoch 36/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7935e-04\n","Epoch 37/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7596e-04\n","Epoch 38/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1281e-04\n","Epoch 39/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0344e-04\n","Epoch 40/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9268e-04\n","Epoch 41/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7003e-04\n","Epoch 42/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6832e-04\n","Epoch 43/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6921e-04\n","Epoch 44/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5807e-04\n","Epoch 45/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7712e-04\n","Epoch 46/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4819e-04\n","Epoch 47/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2856e-04\n","Epoch 48/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5635e-04\n","Epoch 49/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8205e-05\n","Epoch 50/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3890e-05\n","Epoch 51/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1214e-05\n","Epoch 52/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2716e-05\n","Epoch 53/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0450e-05\n","Epoch 54/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3291e-05\n","Epoch 55/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1176e-04\n","Epoch 56/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0099e-05\n","Epoch 57/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3551e-05\n","Epoch 58/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2229e-05\n","Epoch 59/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3489e-05\n","Epoch 60/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.8758e-05\n","Epoch 61/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0994e-05\n","Epoch 62/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7393e-05\n","Epoch 63/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2957e-05\n","Epoch 64/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8618e-05\n","Epoch 65/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4587e-05\n","Epoch 66/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8745e-05\n","Epoch 67/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3886e-05\n","Epoch 68/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7189e-05\n","Epoch 69/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1053e-05\n","Epoch 70/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2751e-05\n","Epoch 71/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4296e-05\n","Epoch 72/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9489e-05\n","Epoch 73/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9586e-05\n","Epoch 74/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0196e-05\n","Epoch 75/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3197e-05\n","Epoch 76/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2776e-05\n","Epoch 77/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8689e-05\n","Epoch 78/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5832e-05\n","Epoch 79/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3425e-05\n","Epoch 80/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2858e-05\n","Epoch 81/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2450e-05\n","Epoch 82/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4870e-05\n","Epoch 83/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3679e-05\n","Epoch 84/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7981e-05\n","Epoch 85/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5605e-05\n","Epoch 86/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7658e-05\n","Epoch 87/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3190e-05\n","Epoch 88/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5097e-05\n","Epoch 89/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3327e-05\n","Epoch 90/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7364e-05\n","Epoch 91/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8999e-05\n","Epoch 92/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9892e-05\n","Epoch 93/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2058e-05\n","Epoch 94/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9626e-05\n","Epoch 95/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3830e-05\n","Epoch 96/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6234e-05\n","Epoch 97/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.1174e-05\n","Epoch 98/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0206e-05\n","Epoch 99/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2947e-05\n","Epoch 100/100\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1419e-05\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a0d142375b0>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# 데이터 예측하기\n","trainPredict = model.predict(X_train)\n","#생성한 인공지능 모델에 데이터를 넣어서 결괏값을 생성하는 predict 함수\n","#훈련 데이터(X_train)의 값을 모델에 넣어 값을 예측\n","#그 예측 값을 trainPredict에 넣음\n","testPredict = model.predict(X_test)\n","#검증 데이터(X_test)의 값을 모델에 넣어 값을 예측\n","#예측 값을 trainPredict에 넣음\n","TrainPredict = scaler.inverse_transform(trainPredict)\n","#생성한 인공지능 모델에 훈련 데이터를 넣어서 얻은 결과가 = trainPredic\n","#trainPredict 에 저장된 값은 0~1사이임 (정규화 과정으로 인해서)\n","#이를 자연수의 형태로 바꾸기 위해서는 훈련 데이터의 예측 값(trainPredict)을 scaler 라이브러리의 inverse_transform 함수를 사용\n","#이 함수를 사용하면 0과 1 사이의 값을 정규화하기 전의 확진자의 수로 바꿀 수 있음\n","Y_train = scaler.inverse_transform([y_train])\n","TestPredict = scaler.inverse_transform(testPredict)\n","Y_test = scaler.inverse_transform([y_test])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jP66EzHpjjLu","executionInfo":{"status":"ok","timestamp":1726988832014,"user_tz":-540,"elapsed":757,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"d7fd402a-dcf8-453d-b017-9543a153d8e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"]}]},{"cell_type":"code","source":["#모델의 정확도 살펴보기\n","trainScore = math.sqrt(mean_squared_error(Y_train[0], TrainPredict[:,0]))\n","# mean_squared_error 함수를 사용\n","# 첫 번째에는 실제 정답값 전체를 가져오기 위해 Y_train[0]을\n","#두 번째에는 예측 값 전체를 가져오기 위해 TrainPredict[:,0]을 넣음\n","#예측 값의 형태가 [:,0]인 이유는 배열이 2차원 배열로 이루어져 있기 때문\n","#평균 제곱근 오차를 구하기 위해 결괏값을 제곱근한 값을 math.sqrt 함수를 사용\n","print('Train Score: %.2f RMSE' % (trainScore))\n","#실수값을 출력할 때에는 %f를 사용\n","#소수 둘째 자리까지만 출력하라는 의미로 %.2f를 입력\n","testScore = math.sqrt(mean_squared_error(Y_test[0], TestPredict[:,0]))\n","#평균 제곱 오차를 구할 때 훈련 데이터의 값((Y_test)과 그 예측 값(TestPredict)을 넣어줌\n","print('Test Score: %.2f RMSE' % (testScore))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gADNXNHwiiPZ","executionInfo":{"status":"ok","timestamp":1726988840378,"user_tz":-540,"elapsed":356,"user":{"displayName":"이Gilbert","userId":"09521568956774973083"}},"outputId":"55cac863-5449-45fd-f8b6-394e15e14ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Score: 4929.09 RMSE\n","Test Score: 39999.47 RMSE\n"]}]},{"cell_type":"code","source":["#결과를 그래프로 확인하기\n","trainPredictPlot = np.empty_like(dataset)\n","#전체 데이터(dataset)와 동일한(np.empty_like) 형태의 넘파이 배열(trainPredictPlot)을 만들어 줌\n","trainPredictPlot[:, :] = np.nan\n","#만들어진 배열의 모든 값을 nan으로 설정\n","#콜론(:)은 모든값을 의미함. (처음):(마지막)에서 처음과 마지막은 생략하고 나타내는 것\n","trainPredictPlot[look_back:len(TrainPredict)+look_back, :] = TrainPredict\n","#처음 3일치는 건너뛰고 4일차(look_back)부터 TrainPredict 배열의 원소 수까지(len(TrainPredict)+look_back)를 범위로 지정\n","testPredictPlot = np.empty_like(dataset)\n","#전체 데이터(dataset)와 동일한(np.empty_like) 넘파이 배열(trainPredictPlot)을 만들어 줌\n","testPredictPlot[:, :] = np.nan\n","#만들어진 배열의 모든 값을 nan으로 설정\n","testPredictPlot[len(TrainPredict)+((look_back+1)*2):len(dataset), :] = TestPredict\n","#검증 데이터를 예측한 결괏값을 그래프로 나타내기 위한 코드\n","#검증 데이터의 예측 값을 넣는 시작점은 훈련 데이터를 예측한 값 이후(len(TrainPredict)+look_back+1)에 3일치의 예측 값을 건너뛴(look_back+1) 자리임\n","plt.plot(dataset)\n","plt.plot(trainPredictPlot)\n","plt.plot(testPredictPlot)\n","plt.show( )"],"metadata":{"id":"nOOwH4nCjoX3"},"execution_count":null,"outputs":[]}]}